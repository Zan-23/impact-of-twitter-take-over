{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a5459f",
   "metadata": {},
   "source": [
    "# Toxicity metrics data generation\n",
    "In this notebook I generate toxicity metrics with the Detoxify library which is used to measure toxicity of texts, in our case tweets. \n",
    "This is meant as a suplementary approach to the Perpective API since we are limited by the number of queries when using it.\n",
    "\n",
    "Make sure to install CUDA achieves at least 5x speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f85e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import random\n",
    "# progress monitoring\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_splitter import split_text_into_sentences\n",
    "# for dealing with fucked up data\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from detoxify import Detoxify\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../../\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302ab77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# clear memory to reduce memory errors\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "# test if cuda is available, it has to be otherwise slow asf, 33 hours for 1.2 million tweets \n",
    "device = torch.device(\"cuda\")\n",
    "cuda_present = torch.cuda.is_available()\n",
    "print(f\"Cuda present: {cuda_present}\")\n",
    "\n",
    "# load the model\n",
    "model = Detoxify('original', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2202c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single predictions\n",
    "model.predict(\"Love on the Spectrum is the cutest show on Netflix rn ðŸ¥¹ðŸ’“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbce06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f577661",
   "metadata": {},
   "source": [
    "## Generating toxicity scores for each tweet\n",
    "The code below needed 19092 seconds (5.3 hours) to run the last time, with CUDA on ~1 million tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for sentence splitting\n",
    "sentences = split_text_into_sentences(\n",
    "    text='This is a paragraph. It contains several sentences. \"But why,\" you ask?',\n",
    "    language='en'\n",
    ")\n",
    "\n",
    "for sent in sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796954b",
   "metadata": {},
   "source": [
    "This is the initial implementation of toxicity generation, without us doing any preprocessing on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO move this to .py file\n",
    "def generate_toxicity_for_tweet_file(input_file, output_file_name):\n",
    "    print(f\"\\nStarted generating toxicity metrics for:\\n\"\n",
    "      f\"-input file: '{input_file}',\\n\"\n",
    "      f\"-output file: '{output_file_name}'\")\n",
    "    tweets_df = pd.read_csv(\"./data/raw_hashtags/\" + input_file)\n",
    "    total_len = len(tweets_df.index)\n",
    "    tweets_df = tweets_df[tweets_df[\"lang\"] == \"en\"]\n",
    "    print(f\"Removed {total_len - len(tweets_df.index)} tweets out of {len(tweets_df.index)}, since they were not in English\")\n",
    "\n",
    "    # if we don't do it, the toxicity metrics will missmatch down the line\n",
    "    tweets_df = tweets_df.reset_index(drop=True)\n",
    "    print(\"Tweet df:\")\n",
    "    display(tweets_df.head(5))\n",
    "\n",
    "    # generating toxicity scores for each tweet\n",
    "    start_time = time.time() \n",
    "    csv_columns = list(tweets_df.columns) + [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"]\n",
    "    toxicity_df = pd.DataFrame(columns=csv_columns)\n",
    "    # save headers to file\n",
    "    toxicity_df.to_csv(output_file_name)\n",
    "    content_list = tweets_df[\"text\"].to_list()\n",
    "    \n",
    "    # multi step - it should work fine now! You can use it and it should be a bit faster\n",
    "    step = 50\n",
    "    for i in range(0, len(tweets_df.index), step):\n",
    "        if i % 500 == 0 and i != 0:\n",
    "            print(f\"At row: {i}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            toxicity_df.to_csv(output_file_name, mode='a', header=False)\n",
    "            print(\"Cleared GPU cache and saved to file\")\n",
    "            toxicity_df = pd.DataFrame(columns=csv_columns)\n",
    "            \n",
    "        curr_tox_dict = model.predict(content_list[i:i+step])\n",
    "        curr_tweet_dict = tweets_df.iloc[i:i+step].reset_index(drop=True).to_dict(orient=\"list\")\n",
    "        merged_tweet_tox = pd.merge(pd.DataFrame(curr_tweet_dict), pd.DataFrame(curr_tox_dict), \n",
    "                                    left_index=True, right_index=True)\n",
    "        toxicity_df = pd.concat([toxicity_df, merged_tweet_tox], ignore_index=True)\n",
    "        \n",
    "    toxicity_df.to_csv(output_file_name, mode='a', header=False)\n",
    "    print(f\"Execution took: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Finished saving to file '{output_file_name}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba7093",
   "metadata": {},
   "source": [
    "Here we implemented a new version of the function above which split the text into sentences and computes the averages over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move this to .py file\n",
    "def upgraded_generate_toxicity_for_tweet_file(input_file, output_file_name):\n",
    "    print(f\"\\nStarted generating toxicity metrics for:\\n\"\n",
    "      f\"-input file: '{input_file}',\\n\"\n",
    "      f\"-output file: '{output_file_name}'\")\n",
    "    tweets_df = pd.read_csv(\"./data/lemmatized/\" + input_file)\n",
    "    total_len = len(tweets_df.index)\n",
    "    tweets_df = tweets_df[tweets_df[\"lang\"] == \"en\"]\n",
    "    print(f\"Removed {total_len - len(tweets_df.index)} tweets out of {len(tweets_df.index)}, since they were not in English\")\n",
    "\n",
    "    # if we don't do it, the toxicity metrics will missmatch down the line\n",
    "    tweets_df = tweets_df.reset_index(drop=True)\n",
    "    print(\"Tweet df:\")\n",
    "    display(tweets_df.head(5))\n",
    "\n",
    "    # generating toxicity scores for each tweet\n",
    "    start_time = time.time() \n",
    "    csv_columns = list(tweets_df.columns) + [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"]\n",
    "    toxicity_df = pd.DataFrame(columns=csv_columns)\n",
    "    # save headers to file\n",
    "    toxicity_df.to_csv(output_file_name)\n",
    "    # changed this column for lemmatized info\n",
    "    content_list_p = tweets_df[\"processed_text\"].to_list()\n",
    "    content_list_raw = tweets_df[\"text\"].to_list()\n",
    "    \n",
    "    # easiest to implement per text\n",
    "    step = 1\n",
    "    for i in tqdm(range(0, len(tweets_df.index), step)):\n",
    "        if i % 5000 == 0 and i != 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            toxicity_df.to_csv(output_file_name, mode='a', header=False)\n",
    "            # print(\"At row: {i}. Cleared GPU cache and saved to file\")\n",
    "            toxicity_df = pd.DataFrame(columns=csv_columns)\n",
    "           \n",
    "        sentences_arr = []\n",
    "        try:\n",
    "            # before predicting, split text into sentences\n",
    "            sentences_arr = split_text_into_sentences(text=content_list_p[i], language='en')\n",
    "        except TypeError as e:\n",
    "            # for handling bad string regex etc.\n",
    "            print(f\"At row {i}, encountered non-sentence splittable string '{content_list_p[i]}'\")\n",
    "            print(f\"Trying to split the original sentence parsed with unidecode '{unidecode(content_list_raw[i])}'!\")\n",
    "            sentences_arr = split_text_into_sentences(text=unidecode(content_list_raw[i]), language='en')\n",
    "            \n",
    "        text_tox_arr = []\n",
    "        for sentence in sentences_arr:\n",
    "            curr_tox_dict = model.predict(sentence)\n",
    "            text_tox_arr.append(curr_tox_dict)\n",
    "\n",
    "        curr_tox_dict = {}\n",
    "        # merge all sentence toxicities and take average (we could also take max)\n",
    "        sentence_count = len(text_tox_arr)\n",
    "        for key in text_tox_arr[0].keys():\n",
    "            curr_tox_dict[key] = sum(tmp_dict[key] for tmp_dict in text_tox_arr) / sentence_count\n",
    "\n",
    "        curr_tweet_dict = tweets_df.iloc[i:i + step].reset_index(drop=True).to_dict(orient=\"list\")\n",
    "        # we have to wrap our dict in an array to be converted to df\n",
    "        merged_tweet_tox = pd.merge(pd.DataFrame(curr_tweet_dict), pd.DataFrame([curr_tox_dict]), \n",
    "                                    left_index=True, right_index=True)\n",
    "        toxicity_df = pd.concat([toxicity_df, merged_tweet_tox], ignore_index=True)\n",
    "        \n",
    "    toxicity_df.to_csv(output_file_name, mode='a', header=False)\n",
    "    print(f\"Execution took: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Finished saving to file '{output_file_name}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe859f",
   "metadata": {},
   "source": [
    "Here we actually run our toxify method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58bc94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hashtag_files = [\"vegetarian_hashtag_6_1_2023.csv\", \"trump_hashtag_04_01_2023.csv\", \"uno_hashtag_09_01_2023.csv\", \n",
    "#                 \"vegan_hashtag_6_1_2023.csv\", \"fitness_hashtag_08_01_2023.csv\", \"musk_hashtag_03_01_2023.csv\",\n",
    "#                \"netflix_hashtag_08_01_2023.csv\"]\n",
    "hashtag_files_lemmatized = [\"netflix_hashtag_08_01_2023_lemmatized.csv\", \"vegetarian_hashtag_6_1_2023_lemmatized.csv\", \n",
    "                            \"uno_hashtag_09_01_2023_lemmatized.csv\", \"vegan_hashtag_6_1_2023_lemmatized.csv\", \n",
    "                            \"fitness_hashtag_08_01_2023_lemmatized.csv\", \"musk_hashtag_03_01_2023_lemmatized.csv\", \n",
    "                            \"trump_hashtag_13_01_2023_lemmatized.csv\"]\n",
    "\n",
    "# to not override files by mistake\n",
    "hash_int = random.randrange(1000)\n",
    "for file_name in hashtag_files_lemmatized:\n",
    "    replaced_str = file_name.replace('.csv', '').replace('_lemmatized', '')\n",
    "    output_file = f\"./data/detoxify_toxicity_added_hashtags/lemmatized_{replaced_str}_detoxify_toxicity_{hash_int}.csv\"\n",
    "    \n",
    "    # old version # generate_toxicity_for_tweet_file(file_name, output_file)\n",
    "    upgraded_generate_toxicity_for_tweet_file(file_name, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5521109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f478818",
   "metadata": {},
   "source": [
    "## Use unicode\n",
    "**unidecode** function automatically converts a string to be more asci compliant. Problem occured at netflix on line ~595628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68accf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473066b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
