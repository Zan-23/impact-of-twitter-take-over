{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a5459f",
   "metadata": {},
   "source": [
    "# Toxicity metrics data generation\n",
    "In this notebook I generate toxicity metrics with the Detoxify library which is used to measure toxicity of texts, in our case tweets. \n",
    "This is meant as a suplementary approach to the Perpective API since we are limited by the number of queries when using it.\n",
    "\n",
    "Make sure to install CUDA achieves at least 5x speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f85e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from detoxify import Detoxify\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../../\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302ab77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# clear memory to reduce memory errors\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "# test if cuda is available, it has to be otherwise slow asf, 33 hours for 1.2 million tweets \n",
    "device = torch.device(\"cuda\")\n",
    "cuda_present = torch.cuda.is_available()\n",
    "print(f\"Cuda present: {cuda_present}\")\n",
    "\n",
    "# load the model\n",
    "model = Detoxify('original', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2202c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single predictions\n",
    "# model.predict(\"#Bridgerton season 2 was satisfying but very slow ... love d end #Netflix\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbce06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"./data/twitter_1_million_tweet_dump_29_12_2022.csv\")\n",
    "total_len = len(tweets_df.index)\n",
    "tweets_df = tweets_df[tweets_df[\"lang\"] == \"en\"]\n",
    "print(f\"Removed {total_len - len(tweets_df.index)} tweets out of {len(tweets_df.index)}, since they were not in English\")\n",
    "\n",
    "# if we don't do it, the toxicity metrics will missmatch down the line\n",
    "tweets_df = tweets_df.reset_index(drop=True)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f577661",
   "metadata": {},
   "source": [
    "## Generating toxicity scores for each tweet\n",
    "The code below needed 19092 seconds (5.3 hours) to run the last time, with CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_file_n = \"toxicity_temp_7_1_single_pred.csv\"\n",
    "# generating toxicity scores for each tweet\n",
    "start_time = time.time() \n",
    "toxicity_df = pd.DataFrame(columns=[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"])\n",
    "toxicity_df.to_csv(csv_file_n)\n",
    "\n",
    "content_list = tweets_df[\"text\"].to_list()\n",
    "\"\"\"\n",
    "# multi step - it should work fine now! You can use it and it should be a bit faster\n",
    "step = 50\n",
    "for i in range(0, len(tweets_df.index), step):\n",
    "    print(f\"At row: {i}\")\n",
    "    # everything in one row to reduce memory consumption\n",
    "    if i % 500 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        toxicity_df.to_csv(csv_file_n, mode='a', header=False)\n",
    "        print(\"Cleared GPU cache and saved to file\")\n",
    "        toxicity_df = pd.DataFrame(columns=[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"])\n",
    "        \n",
    "    toxicity_df = pd.concat([toxicity_df, pd.DataFrame(model.predict(content_list[i:i+step]))], ignore_index=True)\n",
    "\"\"\"\n",
    "for i in range(0, len(tweets_df.index), 1):\n",
    "    # everything in one row to reduce memory consumption\n",
    "    if i % 500 == 0:\n",
    "        print(f\"At row: {i}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        toxicity_df.to_csv(csv_file_n, mode='a', header=False)\n",
    "        print(\"Cleared GPU cache and saved to file\")\n",
    "        toxicity_df = pd.DataFrame(columns=[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"])\n",
    "        \n",
    "    toxicity_df = pd.concat([toxicity_df, pd.DataFrame(model.predict(content_list[i:i+1]))], ignore_index=True)    \n",
    "    \n",
    "toxicity_df.to_csv(csv_file_n, mode='a', header=False)\n",
    "print(f\"Execution took: {time.time() - start_time:.2f} seconds\")\n",
    "display(toxicity_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5521109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv with the toxicity data\n",
    "tox_df = pd.read_csv(csv_file_n)\n",
    "tox_df = tox_df.drop(\"Unnamed: 0\", axis=1)\n",
    "tweets_df = tweets_df.reset_index(drop=True)\n",
    "display(tox_df)\n",
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68accf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing problems with toxicity\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# display(tox_df.iloc[1136439])\n",
    "# display(tweets_df.iloc[1136439])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_f = \"merged_single_pred_toxicity_7_1.csv\"\n",
    "# merge tweets with toxicity and save it to a file\n",
    "merged_toxic_df = pd.merge(tweets_df, tox_df, left_index=True, right_index=True)\n",
    "merged_toxic_df.to_csv(merged_f)\n",
    "display(merged_toxic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_toxic_df.iloc[1136439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac08598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b2eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
