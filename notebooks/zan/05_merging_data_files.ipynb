{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7919274a",
   "metadata": {},
   "source": [
    "## Merging data and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b94d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np≈Ω\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../../\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143b4d3",
   "metadata": {},
   "source": [
    "The code below merged all the 3 data files into a single one with all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581837be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hashtag_tox_tuple = [\n",
    "    ('vegetarian_hashtag_6_1_2023_lemmatized.csv', 'vegetarian_hashtag_6_1_2023_detoxify_toxicity.csv', 'lemmatized_vegetarian_hashtag_6_1_2023_detoxify_toxicity.csv'),\n",
    "    ('fitness_hashtag_08_01_2023_lemmatized.csv', 'fitness_hashtag_08_01_2023_detoxify_toxicity.csv', 'lemmatized_fitness_hashtag_08_01_2023_detoxify_toxicity.csv'),\n",
    "    ('vegan_hashtag_6_1_2023_lemmatized.csv', 'vegan_hashtag_6_1_2023_detoxify_toxicity.csv', 'lemmatized_vegan_hashtag_6_1_2023_detoxify_toxicity.csv'),\n",
    "    ('musk_hashtag_03_01_2023_lemmatized.csv', 'musk_hashtag_03_01_2023_detoxify_toxicity.csv', 'lemmatized_musk_hashtag_03_01_2023_detoxify_toxicity.csv'),\n",
    "    ('netflix_hashtag_08_01_2023_lemmatized.csv', 'netflix_hashtag_08_01_2023_detoxify_toxicity.csv', 'lemmatized_netflix_hashtag_08_01_2023_detoxify_toxicity.csv'),\n",
    "    ('trump_hashtag_13_01_2023_lemmatized.csv', 'trump_hashtag_13_01_2023_detoxify_toxicity.csv', 'lemmatized_trump_hashtag_13_01_2023_detoxify_toxicity.csv'),\n",
    "    ('uno_hashtag_09_01_2023_lemmatized.csv', 'uno_hashtag_09_01_2023_detoxify_toxicity.csv', 'lemmatized_uno_hashtag_09_01_2023_detoxify_toxicity.csv')] \n",
    "data_path = \"./data/detoxify_toxicity_added_hashtags\"\n",
    "\n",
    "tox_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"]\n",
    "normal_tox_dict = {i:f\"normal_{i}\" for i in tox_cols}\n",
    "lemma_tox_dict = {i:f\"lemma_{i}\" for i in tox_cols}\n",
    "\n",
    "for lemma_f, normal_tox_f, lem_tox_f in hashtag_tox_tuple:\n",
    "    out_f_name = f\"./data/preprocessed/{normal_tox_f.split('_')[0]}_hashtag_merged.csv\"\n",
    "    print(normal_tox_f, lem_tox_f, lemma_f, \"\\n\")\n",
    "    print(f\"Started preprocessing, will be saved to file: {out_f_name}\")\n",
    "\n",
    "    normal_df = pd.read_csv(f\"{data_path}/{normal_tox_f}\")[tox_cols]\n",
    "    normal_df = normal_df.rename(columns=normal_tox_dict)\n",
    "    \n",
    "    lemma_tox_df = pd.read_csv(f\"{data_path}/{lem_tox_f}\")[tox_cols]\n",
    "    lemma_tox_df = lemma_tox_df.rename(columns=lemma_tox_dict)\n",
    "    \n",
    "    # get the preprocess text data\n",
    "    lemma_org_df = pd.read_csv(f\"./data/lemmatized/{lemma_f}\")\n",
    "    lemma_org_df = lemma_org_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "    # check the rows where the texts are the same\n",
    "    # display(lemma_org_df[normal_df[\"text\"] == lemma_tox_df[\"processed_text\"]])\n",
    "\n",
    "    # merge all the data into the final dataset\n",
    "    final_data = pd.merge(lemma_org_df, normal_df, left_index=True, right_index=True)\n",
    "    final_data = pd.merge(final_data, lemma_tox_df, left_index=True, right_index=True)\n",
    "    display(final_data.sample(frac=1.0).head(3))\n",
    "    \n",
    "    final_data.to_csv(out_f_name)\n",
    "    print(\"Finished merging and wrote to file!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d13d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
