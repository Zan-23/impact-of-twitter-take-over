{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08fa575f",
   "metadata": {},
   "source": [
    "# Initial analysis of 100k gathered tweets\n",
    "The code presented here was used to build our initial arhitecture and to test out how the data parsing. This should not be refered for forward use since we developed better approaches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51378f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../../\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ea954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"./data/twitter_1_million_tweet_dump_29_12_2022.csv\")\n",
    "display(tweets_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fa891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tweets_df.describe()\n",
    "tweets_in_eng = len(tweets_df[tweets_df[\"lang\"] == \"en\"].index)\n",
    "print(f\"There are {tweets_in_eng} tweets in english\")\n",
    "\n",
    "grouped_by_lang = tweets_df.groupby(\"lang\").count()[[\"tweet_id\"]].reset_index().sort_values(\"tweet_id\", ascending=False)\n",
    "grouped_by_lang.columns = [\"language\", \"count\"]\n",
    "display(grouped_by_lang.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec27349",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_tweet_len = tweets_df[\"text\"].apply(lambda x: len(x)).mean()\n",
    "print(f\"Average length of a tweet in our data set is {average_tweet_len:.2f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50df494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common_words = Counter(\" \".join(tweets_df[\"text\"]).lower().split()).most_common(500)\n",
    "\n",
    "print(\"The 20 most common words in the tweets are:\")\n",
    "for word, count in most_common_words[:20]:\n",
    "    print(f\"{count:<5} '{word}'\")\n",
    "\n",
    "without_stop_words = [(word, count) for word, count in most_common_words if word.lower() not in stop_words]\n",
    "print(\"\\nThe 20 most common words without stop words are in the tweets are:\")\n",
    "for word, count in without_stop_words[:20]:\n",
    "    print(f\"{count:<5} '{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_count = []\n",
    "for word, count in most_common_words:\n",
    "    if word.lower() in (\"#vegan\", \"#vegetarian\", \"#netflix\", \"#fitness\", \"#elon\", \"@elonmusk\"):\n",
    "        hashtags_count.append((word, count))\n",
    "        \n",
    "sorted_hashtags = sorted(hashtags_count, key=lambda x: x[1], reverse=True)\n",
    "print(sorted_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3aba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=[i[0] for i in sorted_hashtags], y=[i[1] for i in sorted_hashtags], text=[i[1] for i in sorted_hashtags])\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Hashtags by their presence in the dataset\", \n",
    "    xaxis_title=\"Hashtag\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f381a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i[1] for i in sorted_hashtags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38f721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
