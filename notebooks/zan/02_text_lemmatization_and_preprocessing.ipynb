{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddd1f16",
   "metadata": {},
   "source": [
    "## Preprocessing text for the Detoxify model\n",
    "\n",
    "In this notebook we took the data we gathered and removed from it unwanted symbols such as emojis, non-english letters etc. with the help of regex. We then proceeded to feed this model through the spacy lemmatization model which derived the base meaning of words from tweets/sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70040f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly \n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from detoxify import Detoxify\n",
    "import spacy\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# download this via \"python -m spacy download en_core_web_sm\"\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "try:\n",
    "    print(run_only_once)\n",
    "except Exception as e:\n",
    "    print(os.getcwd())\n",
    "    os.chdir(\"./../../\")\n",
    "    print(os.getcwd())\n",
    "    run_only_once = \"Dir has already been changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216ac07",
   "metadata": {},
   "source": [
    "Defining the regex which will replace symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols to remove\n",
    "emoji_regex = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\" # TODO this line should be removed/modified else netflix hashtag won't work\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d5c34",
   "metadata": {},
   "source": [
    "## Run Lemmatization\n",
    "This will run lemmatization  on text for all the files, and saved the processed files to `./data/lemmatized/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4419b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_preparation import optimized_prepare_text_for_tweet_file\n",
    "\n",
    "# files that we want to prepare\n",
    "hashtag_files = [\"vegetarian_hashtag_6_1_2023.csv\", \"uno_hashtag_09_01_2023.csv\", \n",
    "                 \"vegan_hashtag_6_1_2023.csv\", \"fitness_hashtag_08_01_2023.csv\", \"netflix_hashtag_08_01_2023.csv\", \n",
    "                 \"musk_hashtag_03_01_2023.csv\", \"trump_hashtag_13_01_2023.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66368c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in hashtag_files[:1]:\n",
    "    output_file = f\"./data/lemmatized/{file.split('.')[0]}_lemmatized.csv\"\n",
    "    optimized_prepare_text_for_tweet_file(replace_symbols_regex=emoji_regex, \n",
    "                                          input_file=file, \n",
    "                                          output_file_name=output_file, \n",
    "                                          nlp_model=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8666a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
