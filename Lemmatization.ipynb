{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "\n",
    "#Change this line to the desired file\n",
    "csvPath = \"C:\\\\Stuff\\\\Seminar\\\\V2\\\\impact-of-twitter-take-over-main\\\\data\\\\twitter_dump_at_time_04_01_2023_17_23_14_TRUMPToxicity.csv\"\n",
    "\n",
    "#Download this via \"python -m spacy download en_core_web_sm\"\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will get the column names\n",
    "column_names = []\n",
    "with open(csvPath) as csv_file:\n",
    "    with open(csvPath,  \"r\",encoding=\"utf-8\") as csvreader:\n",
    "        for row in csvreader:\n",
    "            column_names.append(row)\n",
    "            break \n",
    "column_names = map(lambda s: s.strip(), column_names)\n",
    "    \n",
    "\n",
    "#This will create the second lemmatized file\n",
    "copy = csvPath[:len(csvPath)-4] +\"Lemmatization\" + \".csv\"\n",
    "with open(copy, \"w\", encoding=\"UTF8\", newline=\"\") as writeFile :\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which symbols to remove\n",
    "emoji = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "\n",
    "# This will replace the text in the Tweets\n",
    "#Open Reader and Writer\n",
    "with open(csvPath,  \"r\",encoding=\"utf-8\") as csvfile,open(copy, \"a\", encoding=\"UTF8\", newline=\"\") as writeFile :\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    writer = csv.writer(writeFile)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            rowList = []\n",
    "            \n",
    "            #Copy Original Data\n",
    "            for key in row:\n",
    "                rowList.append(row[key])\n",
    "                \n",
    "              \n",
    "            text = row['text']    \n",
    "            \n",
    "            #Remove Emojis       \n",
    "            text = emoji.sub(r'', text)    \n",
    "            \n",
    "            #Lemmatize\n",
    "            lemmas = nlp(text)\n",
    "            lemmas = ' '.join([x.lemma_ for x in lemmas]) \n",
    "            \n",
    "            #Replace the original text with the Lemma\n",
    "            rowList[4] = lemmas\n",
    "                \n",
    "                \n",
    "            writer.writerow(rowList)\n",
    "        except Exception as e: print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daa0542578263a8a0ea0eb979b6c524f05960ef1c7903d4e0abb944b2dbf19f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
